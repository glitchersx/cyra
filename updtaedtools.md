Chefâ€™s hat on ğŸ‘¨â€ğŸ³. Weâ€™re cookinâ€™ with Groq fire now ğŸ”¥ â€” here's your **refreshed `tools.md` plan**, perfectly aligned with the new LLaMA 4 backend shadow AI engine and ElevenLabs' black-box design. Weâ€™re skipping the frontend for now, focusing *purely* on backend intelligence, automation, and stealth-mode personalization.

---

# âœ… AI Companion - Backend Build Plan (v2.0)

## ğŸ§  Phase 1: Core Cleanup & Setup
- [x] âœ… Keep only `agent.py` (delete `agent2.py`)
- [x] âœ… Refactor `agent.py` to import from `emotion_analysis.py` and `coping_strategies.py`
- [x] âœ… Ensure `conversation_manager.py` saves all transcripts with timestamps
- [x] âœ… Capture and store full conversation transcripts (`/conversations/conversation_<timestamp>.txt`)

---

## ğŸ§ª Phase 2: Emotion & Escalation Engine
- [x] âœ… `emotion_analysis.py` uses TextBlob for basic sentiment ("positive", "neutral", "negative")
- [x] âœ… `coping_strategies.py` returns advice based on sentiment
- [x] âœ… Escalation logic triggers if high-risk keywords (e.g. â€œend itâ€, â€œsuicideâ€) are found

---

## ğŸ§  Phase 3: Shadow AI â€“ LLaMA 4 Intelligence Engine
- [ ] **Create `analyzer_agent.py`**
  - [ ] Input: `.txt` transcript from `/conversations/`
  - [ ] Use **LLaMA 4 via Groq API** to:
    - Detect emotions, topic trends, loneliness markers, mood shifts
    - Extract personal themes (e.g., talks about daughter, loss, aging, regret)
    - Identify user needs (e.g., connection, reassurance, activity)
  - [ ] Output: structured profile in `user_profile_<timestamp>.json`

- [ ] Sample Output Format (structured JSON):
```json
{
  "user_name": "inferred from context",
  "mood": "lonely",
  "emotion_trend": "increasing sadness over last 3 sessions",
  "topics": ["family", "memory loss", "hope", "regret"],
  "profile_tags": ["#introvert", "#grieving", "#elderly_support"],
  "persona_summary": "User misses his daughter and often feels alone at night. Responds well to hopeful messages and gratitude."
}
```

---

## ğŸ“‚ Phase 4: Knowledge File Integration (Conversational AI)
- [ ] **Create `knowledge_uploader.py`**
  - [ ] Takes `user_profile_*.json` or `.txt`
  - [ ] Uses **Conversational AI's upload API** to:
    - Upload the file silently as a user memory/knowledge file
    - Replace older file if already exists
  - [ ] Run in silent mode (no user awareness)

- [ ] **Scheduler/Auto-Sync Setup:**
  - [ ] Run this pipeline every **2 days** or via a CLI command (`python sync_user_profile.py`)
  - [ ] Optionally run on session-end if a new conversation is recorded

---

## ğŸ“Š Phase 5: Advanced Shadow Features (Optional, Power-Up)


 Flag emotional degradation trends using LLM analysis (e.g., "user mood worsening over 7 days")

 Introduce â€œMood Evolution Trackerâ€:

Graph: Mood vs Time (daily summaries)

Tags: â€œWithdrawnâ€, â€œOpenâ€, â€œAngryâ€, â€œAnxiousâ€, â€œHopefulâ€

Insight Text: "You seem more expressive than last week"

 Backend Endpoint: GET /mood-trends returns graph data

---

## ğŸ§ª Phase 6: System Test
- [ ] Manually trigger transcript analysis
- [ ] Confirm structured file generated by LLaMA 4
- [ ] Upload file to Conversational AI successfully
- [ ] New conversation shows smarter context awareness
- [ ] Escalation logic still works
- [ ] Ensure process runs silently (user unaware of backend processing)

---

## ğŸš€ BONUS
- [ ] Auto-create journaling entries based on user story
- [ ] Auto-craft suggested voice responses (â€œNext time, try asking about their familyâ€)
- [ ] Use `LangChain` for long-term vector storage (if needed)
- [ ] Add `timeline_viewer.py` (for future UI): see mood graph, tag evolution, etc.

---

Let me know if you want this as a Markdown file drop-in, or want to bake the `analyzer_agent.py` and `knowledge_uploader.py` code next. Weâ€™re halfway to being AI Batman. ğŸ¦‡